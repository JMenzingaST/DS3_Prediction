{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a brief summary about the following:\n",
    "\n",
    "-\tWhat are common preprocessing steps? Explain for each step why and when you should execute this step and when not.\n",
    "\n",
    "    <b>Answer:</b>\n",
    "\n",
    "    Removing low quality or unwanted observation. <br>\n",
    "    Datasets often contain observations of low quality. These can be removed to imporve the overall quality of the dataset. This does require (some) domain knowledge because you need to determine what low quality observations are\n",
    "\n",
    "    Normalizing the data <br>\n",
    "    Data should be normalized if the different features...\n",
    "\n",
    "-\tWhat visualization methods are used in the cluster methods tutorial? Explain why the selected method is the most appropriate method for the visualization. Bonus points: do this as well for the scanpy tutorial.\n",
    "\n",
    "    <b>Answer:</b>\n",
    "\n",
    "    A histogram is used to plot the distribution of the data. This is an appropriate method because it immideiately gives a clear view of the way the data is distributed, normaly or skewed.\n",
    "\n",
    "    A pairplot is used to display all the different features plotted against eachother on a scatterplot where each point on the plot is colored according to the group (red or white wine in this case) the point belongs in. On the diagonal axis the KDE of a certain feature is displayed. This is a nice visualisation to get an immidiate overview of wether there's separation between categories in the data. With many features this does become a rather big and busy plot so it might not be suitable when there's more then ~ 10 features.\n",
    "\n",
    "    To visualize the inertia, an lineplot is used and each datapoint is accentuated with a dot.\n",
    "    This is a good visualization because it gives a good overview of the decrease in innertia per datapoint by the slope of the line and each inertia 'point' by the dots. This allows the user to identify a cut-off for the n.o. clusters.\n",
    "\n",
    "    To visualize the process of hirarchical clustering, a dendogram is used because it allows the user to follow the process of each pair of datapoints being merged into larger groups per iteration. This then allows for selecting a cut off where you feel like the good amount of clusters should be.\n",
    "\n",
    "    Finally, a lineplot is used to visualize the ROC-AUC over 10 iteration per number of clusters as feature. This because.....\n",
    "    \n",
    "-\tWhat performance/evaluation metrics are in the cluster methods tutorial? Explain why the used methods are the most appropriate method for the evaluation.\n",
    "\n",
    "    <b>Answer:</b>\n",
    "\n",
    "    The inertia is used to evaluate the needed amount of clusters. Where the inertia starts to decrase more slowly, the optimal number of clusters has been reached and clusters will start being cut in half. \n",
    "\n",
    "    If inertia does not provide a good 'cut off' point, distortion might offer a solution. It works on the same principle except that distortion takes in account the number of samples.\n",
    "\n",
    "    Also Receiver Operating Characteristic - Area Under the Curve (ROC-AUC) scores are used to evaluate the perfomance of a binary classification model. \n",
    "\n",
    "    The ROC-AUC score is the area under the ROC curve, which ranges from 0 to 1. A score of 0.5 indicates that the model is performing no better than random chance, while a score of 1.0 indicates perfect classification performance.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus:\n",
    "You practice the steps yourself with the breast_cancer dataset (clustering_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
